{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceCrop_emotion_check.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpUxAYJBtTVPy+/1SRQuyu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canyue1111/TestProject/blob/master/faceCrop_emotion_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "Nm9iDi9v8We1",
        "outputId": "5d755fc3-b1e8-4f33-dbed-1d1f0bd501f7"
      },
      "source": [
        "pip install anvil-uplink"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/65/776713490bfd5145ddb87834355bf7936bd233b273098e37dc12f1ac253c/anvil_uplink-0.3.36-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n",
            "\u001b[?25hCollecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Collecting ws4py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/20/4019a739b2eefe9282d3822ef6a225250af964b117356971bd55e274193c/ws4py-0.5.1.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-cp37-none-any.whl size=45216 sha256=00f5db638436b45f9e50f8d7a5331fe4a91fa35352911484f3d954e599071fe4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/6e/4e/8b0ae12fb9b8a05715256952cf7609a8ab86285fab99b88c68\n",
            "Successfully built ws4py\n",
            "Installing collected packages: argparse, ws4py, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.36 argparse-1.4.0 ws4py-0.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GtyHRBSt4Lb"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      //await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOCiXars3nBW"
      },
      "source": [
        "import dlib\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "from scipy.stats import linregress\n",
        "import anvil.server\n",
        "\n",
        "df = pd.DataFrame(columns =['Customers ID', 'Time', 'Emotion','FileName'] )\n",
        "da = pd.DataFrame(columns =['Customers ID', 'Time', 'Emotion','FileName'] )\n",
        " #(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
        " \n",
        "emotion_class = ['Angry','Disgust','Fear', 'Happy', 'Sad','Surprise','Neutral']\n",
        "\n",
        "model= load_model('ResNet-50.h5')\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "CustomersID = 0\n",
        "CustomerStatus = 0 # 0 means no facedetected, 1 means yes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVH2U1IBVVH2"
      },
      "source": [
        "#Function to load the cropped image\n",
        "def load_image(filename):\n",
        "    img = load_img(filename, grayscale=False, target_size=(197, 197))\n",
        "    #convert to array\n",
        "    img = img_to_array(img)\n",
        "    #reshape into a single sample with  channe 3\n",
        "    img = img.reshape(1, 197, 197, 3)\n",
        "    #prepare pixel data\n",
        "    img = img.astype('float32')\n",
        "    img = img / 255.0\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG80tpmr4P-f"
      },
      "source": [
        "#crop the screenshot\n",
        "def detect_faces(image):\n",
        "    # Run detector and get bounding boxes of the faces on image.\n",
        "    detected_faces = detector(image, 1)\n",
        "    face_frames = [(x.left(), x.top(),\n",
        "                    x.right(), x.bottom()) for x in detected_faces]\n",
        "\n",
        "    return face_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiSgpwVusrZK"
      },
      "source": [
        "def trans_da(n):\n",
        "  #(0=Angry, 1=Disgust, 2=Fear, 5=Happy, 2=Sad, 3=Surprise, 4=Neutral)\n",
        "  if n == 'Angry':\n",
        "    return 1\n",
        "  if n == 'Disgust':\n",
        "    return 1\n",
        "  if n == 'Fear':\n",
        "    return 2\n",
        "  if n == 'Happy':\n",
        "    return 5\n",
        "  if n == 'Sad':\n",
        "    return 2\n",
        "  if n == 'Surprise':\n",
        "    return 4\n",
        "  if n == 'Neutral':\n",
        "    return 3\n",
        "  else: return n\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hQoOqDBe0__"
      },
      "source": [
        "def check_Face_Exist(img_path):\n",
        "  max_score = 0.99\n",
        "  # Detect faces http://dlib.net/face_detector.py.html\n",
        "  img = dlib.load_rgb_image(img_path)\n",
        "  dets, scores, idx = detector.run(img, 1,-1)\n",
        "  for i, d in enumerate(dets):\n",
        "      #print(\"Detection {}, score: {}, face_type:{}\".format(\n",
        "      #    d, scores[i], idx[i]))\n",
        "      if scores[i]> max_score:\n",
        "        max_score = scores[i]\n",
        "  if max_score > 1.0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PUndjK9_QYN"
      },
      "source": [
        "anvil.server.connect(\"E6U72W7FISS5UWOI3GLS4YOX-N2IDQ4SYIEBLIFFM\")\n",
        "\n",
        "@anvil.server.callable\n",
        "def trans_int_da():\n",
        "  return df.to_dict('records')\n",
        "\n",
        "@anvil.server.callable\n",
        "def Customer_Performance(_id):\n",
        "  try:\n",
        "    id = int(_id)\n",
        "    if id in da[\"Customers ID\"].values:\n",
        "      temp = da[da[\"Customers ID\"] == id]\n",
        "      slope, intercept, r_value, p_value, std_err = linregress(temp.index, temp['Emotion'].astype(float))\n",
        "      title_temp = \"Customer ID \"+ str(id) + \" Performance is \"+ str(slope)\n",
        "      return  title_temp\n",
        "    else:  \n",
        "      return \"That \"+ _id +\" Customers ID NOT EXIST\"\n",
        "  except:\n",
        "    return \"Not Valid\"\n",
        "\n",
        "@anvil.server.callable\n",
        "def lastThreeAngry():\n",
        "  #last 3 emotion average is lower than 2.5 and all of them has negative emotion\n",
        "  return (len(da.tail(3)[da['Emotion'] < 4]) == 3) & (da.tail(3)['Emotion'].mean()<2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "P_NRFaTKiJ99",
        "outputId": "5918da65-56c0-456f-b6d6-84691bc93475"
      },
      "source": [
        "update_ = True\n",
        "\n",
        "img_path = 'photo.jpg'\n",
        "\n",
        "while update_:\n",
        "  time.sleep(2)\n",
        "\n",
        "  filename = take_photo()\n",
        "\n",
        "  if check_Face_Exist(img_path):\n",
        "    print(\"Face Detected\")\n",
        "    CustomerStatus = 1\n",
        "    image = io.imread(img_path)\n",
        "    detected_faces = detect_faces(image)\n",
        "\n",
        "  # Crop faces and plot\n",
        "    for n, face_rect in enumerate(detected_faces):\n",
        "      face = Image.fromarray(image).crop(face_rect)\n",
        "\n",
        "      now = datetime.now()\n",
        "      today = now.strftime(\"%H:%M:%S\")\n",
        "      #file name setting\n",
        "      name = str(today) + '.png'\n",
        "      #save file\n",
        "      plt.savefig(name)\n",
        "\n",
        "      # emotion_class[np.argmax(model.predict(load_image(\"file/\" + name)))]\n",
        "      addition=pd.DataFrame( {'Customers ID': [CustomersID],\n",
        "        'Time': [today],'Emotion':  [emotion_class[np.argmax(model.predict(load_image(name)))]],'FileName':[name]})\n",
        "      df = df.append(addition, ignore_index=True)\n",
        "      addition['Emotion'] = addition['Emotion'].apply(trans_da)\n",
        "      da = da.append(addition, ignore_index=True)\n",
        "    plt.subplot(1, len(detected_faces), n+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(face)\n",
        "  \n",
        "  else:\n",
        "    print(\"NofaceDetected\")\n",
        "    if CustomerStatus == 1:\n",
        "      CustomerStatus = 0\n",
        "      CustomersID = CustomersID + 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-91ba834178b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mupdate_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "3oKf3KolIkW5",
        "outputId": "b5aeb8ea-4f96-40fa-8283-9bdec492b5ce"
      },
      "source": [
        "da"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customers ID</th>\n",
              "      <th>Time</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>FileName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14:33:04</td>\n",
              "      <td>4</td>\n",
              "      <td>14:33:04.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>14:33:05</td>\n",
              "      <td>4</td>\n",
              "      <td>14:33:05.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>14:33:12</td>\n",
              "      <td>4</td>\n",
              "      <td>14:33:12.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14:33:13</td>\n",
              "      <td>4</td>\n",
              "      <td>14:33:13.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>14:33:20</td>\n",
              "      <td>4</td>\n",
              "      <td>14:33:20.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>12</td>\n",
              "      <td>15:06:40</td>\n",
              "      <td>4</td>\n",
              "      <td>15:06:40.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>12</td>\n",
              "      <td>15:06:44</td>\n",
              "      <td>4</td>\n",
              "      <td>15:06:44.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>12</td>\n",
              "      <td>15:06:44</td>\n",
              "      <td>4</td>\n",
              "      <td>15:06:44.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>12</td>\n",
              "      <td>15:06:49</td>\n",
              "      <td>4</td>\n",
              "      <td>15:06:49.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>12</td>\n",
              "      <td>15:06:53</td>\n",
              "      <td>2</td>\n",
              "      <td>15:06:53.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>168 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Customers ID      Time Emotion      FileName\n",
              "0              0  14:33:04       4  14:33:04.png\n",
              "1              0  14:33:05       4  14:33:05.png\n",
              "2              0  14:33:12       4  14:33:12.png\n",
              "3              0  14:33:13       4  14:33:13.png\n",
              "4              0  14:33:20       4  14:33:20.png\n",
              "..           ...       ...     ...           ...\n",
              "163           12  15:06:40       4  15:06:40.png\n",
              "164           12  15:06:44       4  15:06:44.png\n",
              "165           12  15:06:44       4  15:06:44.png\n",
              "166           12  15:06:49       4  15:06:49.png\n",
              "167           12  15:06:53       2  15:06:53.png\n",
              "\n",
              "[168 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_ejOrsd1Bmi",
        "outputId": "58774e3b-1af5-497c-ba92-ea617c7832e0"
      },
      "source": [
        "(len(da.tail(3)[da['Emotion'] < 4]) == 3) & (da.tail(3)['Emotion'].mean()<2.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xeoISc3w_9S"
      },
      "source": [
        "#EDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfZ2kI9QxER9"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def Customer_Performance(_id,_dataframe):\n",
        "  temp = _dataframe[_dataframe[\"Customers ID\"] == _id]\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(_dataframe.index,_dataframe['Emotion'])\n",
        "  title_temp = \"Customer ID \"+ str(_id) + \" Performance is \"+ str(slope)\n",
        "  sns.regplot(x=_dataframe.index, y=\"Emotion\", data=_dataframe, fit_reg=True).set_title(title_temp)\n",
        "  display(temp,slope)\n",
        "\n",
        "#if ask which kind of customers\n",
        "Customer_Performance(0,da)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj_sAJWXxcmr"
      },
      "source": [
        "temp = df.loc[:,['Customers ID','Time']]\n",
        "visualizable_feature_names = temp.columns #\n",
        "\n",
        "labels = df['Emotion'].unique() \n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig_hist = []\n",
        "for i, feature_name in enumerate(visualizable_feature_names):\n",
        "    fig_hist.append(go.Figure())\n",
        "    for label in labels:\n",
        "        fig_hist[i].add_trace(go.Histogram(x=df[df[\"Emotion\"]==label][feature_name], name=label))\n",
        "    fig_hist[i].update_layout(height=400, width=800, title_text=feature_name)\n",
        "    fig_hist[i].update_layout(barmode='overlay')\n",
        "    fig_hist[i].update_traces(opacity=0.5)\n",
        "    fig_hist[i].show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}